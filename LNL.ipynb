{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Add, Multiply, Dense, Input, Activation\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "def get_session(gpu_fraction=0.5):\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "\n",
    "def makeModel(N, order=1):\n",
    "    \"\"\"\n",
    "    To run the model, use the following:\n",
    "\n",
    "    model = makeModel(n_dimensions, order)\n",
    "    model.fit(X, Y, epochs=n_epochs, callbacks=[keras.callbacks.EarlyStopping()], validation_split=0.25)\n",
    "\n",
    "    For the linear model, model.get_weights() returns the linear weights and the bias.\n",
    "    For the quadratic model, model.get_weights() returns quadratic weights, dummy weights, linear weights, and the bias.\n",
    "    \"\"\"\n",
    "    KTF.set_session(get_session())\n",
    "\n",
    "    inLayer = Input((N,))\n",
    "    linear = Dense(1, name='Linear')(inLayer)\n",
    "    if order == 2:\n",
    "        quad1 = Dense(N, kernel_initializer=keras.initializers.random_normal(stddev=0.001),\n",
    "                      use_bias=False, name='Quad')(inLayer)\n",
    "        quad2 = Multiply()([quad1, inLayer])\n",
    "        quad3 = Dense(1, kernel_initializer='ones', use_bias=False, trainable=False)(quad2)\n",
    "        x = Add()([quad3, linear])\n",
    "        outLayer = Activation('sigmoid')(x)\n",
    "    else:\n",
    "        outLayer = Activation('sigmoid')(linear)\n",
    "    model = Model(inLayer, outLayer)\n",
    "    model.compile('rmsprop', 'binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_MNE(stimuli, spike_probs, order=2, val_split=0.25):\n",
    "    \"\"\"\n",
    "    Creates and fits a MNE model\n",
    "\n",
    "    Inputs:\n",
    "    stimuli - numpy array of the stimuli.  Of shape (number of samples,dimension of stimulus)\n",
    "    spike_probs - numpy array of the spiking probabilities.  Of shape (number of samples)\n",
    "\n",
    "    order - The order of the MNE fit.  \n",
    "        1 = first order linear filters only (standard logistic regression).  \n",
    "        2 = also fit second order quadratic kernels.\n",
    "    \n",
    "    val_split - what percentage of data to set aside for early stopping on the validation set.  \n",
    "        This will be lopped off the end of stimuli and spike_probs so I recommend having shuffled stimuli \n",
    "        and spike_probs initially. That way the validation split roughly matches the training distribution.\n",
    "\n",
    "    Outputs:\n",
    "    results - A python dictionary with resulting fitted parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    dim_x = stimuli.shape[1]\n",
    "    model = makeModel(dim_x, order=order)\n",
    "\n",
    "    model.fit(stimuli, spike_probs, verbose=0, epochs=40, \n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=2)], validation_split=val_split)\n",
    "    if order == 1:\n",
    "        w, bias = model.get_weights()\n",
    "        results = {\"linear\": w, \"bias\": bias}\n",
    "    else:\n",
    "        J, dummy, w, bias = model.get_weights()\n",
    "        J_sym = 0.5 * (J + np.transpose(J))\n",
    "        results = {\"quadratic\": J_sym, \"linear\": w, \"bias\": bias}\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'F:/NHP/AD8/Ephys/20161205/hartley_gray'\n",
    "trials_path = glob.glob(data_folder + '/trials.csv')[0]\n",
    "\n",
    "trials = pd.read_csv(trials_path, index_col=0)\n",
    "total_time = int(np.round(trials.stim_time[trials.index[-1]] - trials.stim_time[0]))\n",
    "t_index = np.arange(0, total_time, 0.001)\n",
    "stim = pd.DataFrame(np.zeros([total_time*1000, 2]), columns=['sfx', 'sfy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = sio.loadmat(\"C:\\\\Users\\\\anupam\\\\Dropbox\\\\NHP cells\\\\spike_times_1.mat\")['spike_times']\n",
    "st_shift = st - trials.stim_time[0]\n",
    "st_bins = np.histogram(st, bins=t_index)[0]\n",
    "\n",
    "stim_time_shift = trials.stim_time - trials.stim_time[0]\n",
    "stim_time_idx = np.searchsorted(stim_time_shift, t_index, side='right') - 1\n",
    "stim_bins = trials.loc[stim_time_idx[:-1], ['sf_x', 'sf_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNE_test = train_MNE(stim_bins.as_matrix(), st_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': array([-16.11840248], dtype=float32), 'linear': array([[-7.86706543],\n        [ 0.15429549]], dtype=float32), 'quadratic': array([[-7.00103807,  0.1253639 ],\n        [ 0.1253639 , -7.06098032]], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stim = stim_bins.drop_duplicates().as_matrix()\n",
    "term_lin = term2 = np.dot(MNE_test['linear'].T, unique_stim.T)\n",
    "bias = MNE_test['bias']\n",
    "spike_prob = 1 / (1 + np.exp((term_lin + bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEDCAYAAAAyZm/jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6UYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1315fc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(spike_prob)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        , ...,  1.        ,\n         0.99999995,  0.99999994]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
